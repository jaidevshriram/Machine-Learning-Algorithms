{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwGWNHs2xIsx"
   },
   "source": [
    "# Logistic Regression Excercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcaBeePgu_Tu"
   },
   "source": [
    "## Multi-class classification of MNIST using Logistic Regression\n",
    "\n",
    "The multi-class scenario for logistic regression is quite similar to the binary case, except that the label $y$ is now an integer in {1, ...., K} where $K$ is the number of classes. In this excercise you will be provided with handwritten digit images. Write the code and compute the test accuracy by training a logistic regression based classifier in (i) one-vs-one, and (ii) one-vs-all setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running importer\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        #print('searching: %s'%nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        #print('searching: %s' % nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        #print('Found %d cells'%len(nb.cells))\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "\n",
    "#  register the NotebookFinder with sys.meta_path\n",
    "print('running importer')\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9944,
     "status": "ok",
     "timestamp": 1596983406360,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "ManRVu7IsIjp",
    "outputId": "b48dd937-f2d5-4762-af1a-44fa03c44d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "from utils import plot_decision_boundary, get_accuracy, get_prediction\n",
    "from utils import plot_2D_input_datapoints, generate_gifs, sigmoid, normalize\n",
    "import math\n",
    "import gif\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9918,
     "status": "ok",
     "timestamp": 1596983406361,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "xbV2U06Cs45b"
   },
   "outputs": [],
   "source": [
    "# Let's initialize our weights using uniform distribution\n",
    "def weight_init_uniform_dist(X, y):\n",
    "  \n",
    "    np.random.seed(312)\n",
    "    n_samples, n_features = np.shape(X)\n",
    "    _, n_outputs = np.shape(y)\n",
    "\n",
    "    limit = 1 / math.sqrt(n_features)\n",
    "    weights = np.random.uniform(-limit, limit, (n_features, n_outputs))\n",
    "    weights[-1] = 0\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36195,
     "status": "ok",
     "timestamp": 1596983432936,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "SAAbK03fLCR1"
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "# One hot encoding of our output label vector y\n",
    "def one_hot(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    return b\n",
    "\n",
    "# Loading dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Absorbing weight b of the hyperplane\n",
    "X = digits.data\n",
    "b_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, b_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36177,
     "status": "ok",
     "timestamp": 1596983432939,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "yzdjTbEYLvPK",
    "outputId": "76ed5c87-3298-433d-cf76-d68026c46342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig()\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36148,
     "status": "ok",
     "timestamp": 1596983432942,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "3CIYTv4x65As",
    "outputId": "d9f59ee0-8392-4ba9-8cb8-11afc1669fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1308, 65)\n",
      "Validation dataset:  (188, 65)\n",
      "Test dataset:  (301, 65)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into train, val, and test set.\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.167)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36132,
     "status": "ok",
     "timestamp": 1596983432945,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "d3NzkO4s68RX"
   },
   "outputs": [],
   "source": [
    "# Normalizing X_train and absorbing weight b of the hyperplane\n",
    "X_normalized_train = normalize(X_train[:, :64])\n",
    "\n",
    "b_ones = np.ones((len(X_normalized_train), 1))\n",
    "X_normalized_train = np.hstack((X_normalized_train, b_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36096,
     "status": "ok",
     "timestamp": 1596983432947,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "pYrK4fK3iyyk",
    "outputId": "a73d5605-db30-4099-f72e-9cca8e2fe3cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vs_one(x, y, base_weights, num_epochs=1000, learning_rate=0.1):\n",
    "\n",
    "    \"\"\"Method to train a multiclass classifier using one vs one technique.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "\n",
    "    X_train: ndarray (num_examples(rows) vs num_columns(columns))\n",
    "    Input data on which the logistic regression model will be trained \n",
    "    to acquire optimal weights\n",
    "\n",
    "    Y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    Class labels of training set\n",
    "\n",
    "    base_weights: ndarray (num_features vs n_outputs)\n",
    "    Weights used to train the network and predict on test set\n",
    "\n",
    "    num_epochs: int\n",
    "    Number of epochs you want to train the model\n",
    "\n",
    "    learning_rate: int\n",
    "    rate with which weights will be update every epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples, n_features = np.shape(x)\n",
    "\n",
    "    history_weights = []\n",
    "    class_compare = []\n",
    "    weights_k_classes = []\n",
    "    epoch = 1\n",
    "\n",
    "    backup_X_train = copy.deepcopy(x)\n",
    "    \n",
    "    y = np.array([np.where(r==1)[0][0] for r in y])\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    classes = sorted(np.unique(y))\n",
    "\n",
    "    # Training using Batch GD\n",
    "    for k in classes:\n",
    "        for l in classes:\n",
    "            \n",
    "            x = copy.deepcopy(backup_X_train)\n",
    "            \n",
    "            if k == l or l < k:\n",
    "                continue\n",
    "            \n",
    "            temp_Y_train_k = np.where((y == k))[0]\n",
    "            temp_Y_train_l = np.where((y == l))[0]\n",
    "            temp_Y_train = sorted(np.append(temp_Y_train_k, temp_Y_train_l))\n",
    "            \n",
    "            # one-vs-all binary classifier\n",
    "            x = x[temp_Y_train]\n",
    "            temp_Y_train = y[temp_Y_train]\n",
    "            \n",
    "            binary_y_train = np.where(temp_Y_train == k, 1, 0)\n",
    "\n",
    "            weights = base_weights\n",
    "            \n",
    "            # Appending previous history weights/first initialized weights\n",
    "\n",
    "            for epoch in range(1, num_epochs+1):\n",
    "\n",
    "                # Computing weighted inputs and predicting output\n",
    "                w_transpose_x = np.dot(x, weights)\n",
    "                y_pred = sigmoid(w_transpose_x)\n",
    "\n",
    "                # Calculating gradient and updating weights\n",
    "                gradient = 1 * np.dot(x.T, (binary_y_train - y_pred))\n",
    "                weights += (learning_rate/n_samples) * gradient\n",
    "                weights = np.round(weights, decimals=7)\n",
    "\n",
    "                #weights_k_classes.append(weights)\n",
    "                epoch += 1\n",
    "\n",
    "            #history_weights.append(weights_k_classes)\n",
    "            history_weights.append(weights)\n",
    "            class_compare.append([k, l])\n",
    "\n",
    "    print(\"Training complete\")\n",
    "    return history_weights, class_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Initializing weights from uniform distribution\n",
    "weights = weight_init_uniform_dist(X_train, np.array([np.where(r==1)[0][0] for r in Y_train]).reshape(-1, 1))\n",
    "trained_weights, class_compare = train_one_vs_one(X_train, Y_train, weights, num_epochs=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of training data and validation data\n",
    "def predict_one_vs_one(trained_weights, X_input, Y_input):\n",
    "  \n",
    "    num_classes = 10\n",
    "    scores = np.zeros((num_classes, (X_input.shape)[0]))\n",
    "\n",
    "    i = 0\n",
    "    for k in range(num_classes):\n",
    "        for l in range(num_classes):\n",
    "                \n",
    "            if k == l or l < k:\n",
    "                continue    \n",
    "\n",
    "            w_transpose_x = np.dot(X_input, trained_weights[i])\n",
    "            y_pred = sigmoid(w_transpose_x)\n",
    "            y_pred = y_pred[:, 0]\n",
    "            \n",
    "            scores[class_compare[i][0], :] += y_pred\n",
    "            scores[class_compare[i][1], :] += 1 - y_pred\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "    pred_X = np.argmax(scores, axis=0)\n",
    "#     print(pred_X)\n",
    "    return pred_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_f(y, pred):\n",
    "    y = np.array([np.where(r==1)[0][0] for r in y])\n",
    "    y = y.reshape(-1, 1)\n",
    "        \n",
    "#     print(y[:,0], pred[:,0])\n",
    "    return np.mean(y == pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset accuracy: 1.000000\n",
      "Validation dataset accuracy: 0.968085\n",
      "Test datast accuracy: 0.973422\n"
     ]
    }
   ],
   "source": [
    "pred_train_one_vs_one = predict_one_vs_one(trained_weights, X_train, Y_train)\n",
    "pred_val_one_vs_one = predict_one_vs_one(trained_weights, X_val, Y_val)\n",
    "pred_test_one_vs_one = predict_one_vs_one(trained_weights, X_test, Y_test)\n",
    "\n",
    "pred_train_one_vs_one = pred_train_one_vs_one.reshape((-1, 1))\n",
    "pred_val_one_vs_one = pred_val_one_vs_one.reshape((-1, 1))\n",
    "pred_test_one_vs_one = pred_test_one_vs_one.reshape((-1, 1))\n",
    "\n",
    "print('Training dataset accuracy: %f' % (get_accuracy_f(Y_train, pred_train_one_vs_one)))\n",
    "print('Validation dataset accuracy: %f' % (get_accuracy_f(Y_val, pred_val_one_vs_one)))\n",
    "print('Test datast accuracy: %f' % (get_accuracy_f(Y_test, pred_test_one_vs_one)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vs_all(X_train, Y_train, base_weights, num_epochs=1000, learning_rate=0.1):\n",
    "\n",
    "    \"\"\"Method to train a multiclass classifier using one vs all technique.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "\n",
    "    X_train: ndarray (num_examples(rows) vs num_columns(columns))\n",
    "    Input data on which the logistic regression model will be trained \n",
    "    to acquire optimal weights\n",
    "\n",
    "    Y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    Class labels of training set\n",
    "\n",
    "    base_weights: ndarray (num_features vs n_outputs)\n",
    "    Weights used to train the network and predict on test set\n",
    "\n",
    "    num_epochs: int\n",
    "    Number of epochs you want to train the model\n",
    "\n",
    "    learning_rate: int\n",
    "    rate with which weights will be update every epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples, n_features = np.shape(X_train)\n",
    "\n",
    "    history_weights = []\n",
    "    weights_k_classes = []\n",
    "    epoch = 1\n",
    "\n",
    "    Y_train = np.array([np.where(r==1)[0][0] for r in Y_train])\n",
    "    Y_train = Y_train.reshape(-1, 1)\n",
    "    \n",
    "    classes = np.unique(Y_train)\n",
    "\n",
    "    # Training using Batch GD\n",
    "    for k in classes:\n",
    "        # one-vs-all binary classifier\n",
    "        binary_y_train = np.where(Y_train == k, 1, 0)\n",
    "\n",
    "        weights = base_weights\n",
    "        # Appending previous history weights/first initialized weights\n",
    "        #weights_k_classes.append(weights)\n",
    "\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "            # Computing weighted inputs and predicting output\n",
    "            w_transpose_x = np.dot(X_train, weights)\n",
    "            y_pred = sigmoid(w_transpose_x)\n",
    "\n",
    "            # Calculating gradient and updating weights\n",
    "            gradient = 1 * np.dot(X_train.T, (binary_y_train - y_pred))\n",
    "            weights += (learning_rate/n_samples) * gradient\n",
    "            weights = np.round(weights, decimals=7)\n",
    "\n",
    "            #weights_k_classes.append(weights)\n",
    "            epoch += 1\n",
    " \n",
    "        #history_weights.append(weights_k_classes)\n",
    "        history_weights.append(weights)\n",
    "        #weights_k_classes = []\n",
    "\n",
    "    print(\"Training complete\")\n",
    "    return history_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Initializing weights from uniform distribution\n",
    "weights = weight_init_uniform_dist(X_train, Y_train)\n",
    "trained_weights = train_one_vs_all(X_train, Y_train, weights, num_epochs=1000, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of training data and validation data\n",
    "def predict_one_vs_all(trained_weights, X_input, Y_input):\n",
    "  \n",
    "    num_classes = 10\n",
    "    scores = np.zeros((num_classes, (X_input.shape)[0]))\n",
    "\n",
    "    for k in range(num_classes):\n",
    "    \n",
    "        binary_y_input = np.where(Y_input == k, 1, 0)\n",
    "\n",
    "        w_transpose_x = np.dot(X_input, trained_weights[k])\n",
    "        y_pred = sigmoid(w_transpose_x)\n",
    "        y_pred = y_pred[:, 0]\n",
    "#         print(y_pred.shape)\n",
    "        \n",
    "        scores[k, :] = y_pred\n",
    "\n",
    "    pred_X = np.argmax(scores, axis=0)\n",
    "    return pred_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset accuracy: 0.981651\n",
      "Validation dataset accuracy: 0.957447\n",
      "Test datast accuracy: 0.950166\n"
     ]
    }
   ],
   "source": [
    "pred_train_one_vs_all = predict_one_vs_all(trained_weights, X_train, Y_train)\n",
    "pred_val_one_vs_all = predict_one_vs_all(trained_weights, X_val, Y_val)\n",
    "pred_test_one_vs_all = predict_one_vs_all(trained_weights, X_test, Y_test)\n",
    "\n",
    "pred_train_one_vs_all = pred_train_one_vs_all.reshape((-1, 1))\n",
    "pred_val_one_vs_all = pred_val_one_vs_all.reshape((-1, 1))\n",
    "pred_test_one_vs_all = pred_test_one_vs_all.reshape((-1, 1))\n",
    "\n",
    "print('Training dataset accuracy: %f' % (get_accuracy_f(Y_train, pred_train_one_vs_all)))\n",
    "print('Validation dataset accuracy: %f' % (get_accuracy_f(Y_val, pred_val_one_vs_all)))\n",
    "print('Test datast accuracy: %f' % (get_accuracy_f(Y_test, pred_test_one_vs_all)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LogisticRegression_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
