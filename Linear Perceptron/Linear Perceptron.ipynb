{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwxWcO7fqb-L"
   },
   "source": [
    "# Excercise - Multi-class classification of MNIST using Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcygblmOmQDZ"
   },
   "source": [
    "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
    "\n",
    "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
    "vector, and leaving alone an other weight vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the utils notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gif\n",
      "Collecting Pillow>=7.1.2 (from gif)\n",
      "  Using cached https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: Pillow, gif\n",
      "Successfully installed Pillow-7.2.0 gif-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "\n",
    "I have imported some functions from utils, that is the only change made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223975,
     "status": "ok",
     "timestamp": 1596984132348,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "gNkGLnbjTY-s"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "# np.random.seed(11)\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "def one_hot(a):\n",
    "  b = -1 * np.ones((a.size, a.max()+1))\n",
    "  b[np.arange(a.size), a] = 1\n",
    "  return b\n",
    "\n",
    "# Loading digits datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "X = digits.data\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223957,
     "status": "ok",
     "timestamp": 1596984132353,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "0BPvc5P8KvrM",
    "outputId": "233f09b1-7641-4c60-c21d-74a2264f8bc3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1257, 65)\n",
      "Validation dataset:  (180, 65)\n",
      "Test dataset:  (360, 65)\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test data\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223939,
     "status": "ok",
     "timestamp": 1596984132358,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "QPJZdeDtUfoy",
    "outputId": "66a50417-5c21-4158-f029-20ef755e50f4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig();\n",
    "\n",
    "# print(digits.data[:20])\n",
    "# print(digits.target[:20])\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2KVp57S1Zah"
   },
   "source": [
    "# Utility Functions\n",
    "\n",
    "We use some functions defined in the earlier - utils.py notebook. \n",
    "Notably, we use the multi class signum function which helps us train 10 perceptrons at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class signum\n",
    "def multi_class_signum(vec_w_x):\n",
    "  \"\"\" Multiclass signum activation.\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  vec_w_x: ndarray\n",
    "    Weighted inputs\n",
    "  \"\"\"\n",
    "\n",
    "  flag = np.all(vec_w_x == 0)\n",
    "\n",
    "  if flag:\n",
    "    return vec_w_x\n",
    "\n",
    "  else:\n",
    "    num_examples, num_outputs = np.shape(vec_w_x)\n",
    "    range_examples = np.array(range(0, num_examples))\n",
    "\n",
    "    zero_idxs = np.argwhere(np.all(vec_w_x == 0, axis=1))\n",
    "    non_zero_examples = np.delete(range_examples, zero_idxs[:, 0])\n",
    "      \n",
    "    signum_vec_w_x = vec_w_x[non_zero_examples]\n",
    "    maxvals = np.amax(signum_vec_w_x, axis=1)\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "      idx = np.argwhere(signum_vec_w_x == maxvals[i])[0]\n",
    "      signum_vec_w_x[idx[0], idx[1]] = 1\n",
    "\n",
    "    non_maxvals_idxs = np.argwhere(signum_vec_w_x != 1)\n",
    "    signum_vec_w_x[non_maxvals_idxs[:, 0], non_maxvals_idxs[:, 1]] = -1\n",
    "    vec_w_x[non_zero_examples] = signum_vec_w_x\n",
    "\n",
    "    return vec_w_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for train, val, and test set.\n",
    "def get_accuracy(y_predicted, Y_input_set, num_datapoints):\n",
    "  miscls_points = np.argwhere(np.any(y_predicted != Y_input_set, axis=1))\n",
    "  miscls_points = np.unique(miscls_points)\n",
    "  accuracy = (1-len(miscls_points)/num_datapoints)*100\n",
    "  return accuracy\n",
    "\n",
    "def get_prediction(X_input_set, Y_input_set, weights, get_acc=False, model_type='perceptron', predict='no'):\n",
    "\n",
    "  if len(Y_input_set) != 0:\n",
    "    num_datapoints, num_categories = np.shape(Y_input_set)\n",
    "\n",
    "  vec_w_transpose_x = np.dot(X_input_set, weights)\n",
    "\n",
    "  if num_categories > 1: # Multi-class\n",
    "    if model_type == 'perceptron':\n",
    "      y_pred_out = multi_class_signum(vec_w_transpose_x)\n",
    "    elif model_type == 'logreg':\n",
    "      y_pred_out = softmax(X_input_set, vec_w_transpose_x, predict=predict)\n",
    "\n",
    "  else: # Binary class\n",
    "    if model_type == 'perceptron' or model_type == 'LinearDA':\n",
    "      y_pred_out = signum(vec_w_transpose_x)\n",
    "    elif model_type == 'logreg':\n",
    "      y_pred_out = sigmoid(vec_w_transpose_x, predict=predict)\n",
    "\n",
    "  # Both prediction and evaluation\n",
    "  if get_acc:\n",
    "    cls_acc = get_accuracy(y_pred_out, Y_input_set, num_datapoints)\n",
    "    return cls_acc, y_pred_out\n",
    "  \n",
    "  # Only prediction\n",
    "  return y_pred_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "We train a set of perceptrons simultaneously here, using the multi_class_signum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron training algorithm\n",
    "def train(X_train, Y_train, weights, learning_rate=1, total_epochs=100):\n",
    "    \"\"\"Training method for Perceptron.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "    X_train: ndarray (num_examples(rows) vs num_features(columns))\n",
    "    Input dataset which perceptron will use to learn optimal weights\n",
    "\n",
    "    Y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    Class labels for input data\n",
    "\n",
    "    weights: ndarray (num_features vs n_output)\n",
    "    Weights used to train the network and predict on test set\n",
    "\n",
    "    learning_rate: int\n",
    "    Learning rate use to learn and update weights\n",
    "\n",
    "    total_epochs: int\n",
    "    Max number of epochs to train the perceptron model\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples, _ = np.shape(X_train)\n",
    "    history_weights = []\n",
    "    epoch = 1\n",
    "\n",
    "    # Number of missclassified points we would like to see in the train set.\n",
    "    # While training, its value will change every epoch. If m==0, our training \n",
    "    # error will be zero.\n",
    "    m = 1\n",
    "\n",
    "    # If the most recent weights gave 0 misclassifications, break the loop.\n",
    "    # Else continue until total_epochs is completed.\n",
    "    while m != 0 and epoch <= total_epochs:\n",
    "        m = 0\n",
    "        \n",
    "        # Compute weighted inputs and predict class labels on training set.\n",
    "        weights_transpose_x = multi_class_signum(X_train @ weights)\n",
    "        y_train_out = np.multiply(Y_train, weights_transpose_x)\n",
    "        epoch += 1\n",
    "\n",
    "        # Collecting misclassified indexes and count them\n",
    "        y_miscls_idxs = np.argwhere(y_train_out <= 0)[:, 0]\n",
    "        y_miscls_idxs = np.unique(y_miscls_idxs)\n",
    "        m = len(y_miscls_idxs)\n",
    "\n",
    "        # Calculate gradients and update weights\n",
    "        dweights = (X_train[y_miscls_idxs]).T @ Y_train[y_miscls_idxs]\n",
    "        weights += (learning_rate/n_samples) * dweights\n",
    "\n",
    "        # Append weights to visualize decision boundary later\n",
    "        history_weights.append(weights)\n",
    "\n",
    "    if epoch < total_epochs:\n",
    "        print(\"Training has stabilized with all points classified: \", epoch)\n",
    "    else:\n",
    "        print(f'Training completed at {epoch-1} epochs. {m} misclassified points remain.')\n",
    "\n",
    "    return history_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing weights to zero\n",
    "_, n_features = np.shape(X_train)\n",
    "_, n_outputs = np.shape(Y_train)\n",
    "\n",
    "weights = np.zeros((n_features, n_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed at 100 epochs. 53 misclassified points remain.\n"
     ]
    }
   ],
   "source": [
    "trained_weights = train(X_train, Y_train, weights, learning_rate=0.05, total_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results\n",
      "Training accuracy: 95.465\n",
      "Validation accuracy: 96.667\n",
      "Test accuracy: 91.667\n"
     ]
    }
   ],
   "source": [
    "best_weights = trained_weights[-1]\n",
    "\n",
    "train_acc, _ = get_prediction(X_train, Y_train, best_weights, get_acc=True)\n",
    "val_acc, _ = get_prediction(X_val, Y_val, best_weights, get_acc=True)\n",
    "test_acc, _ = get_prediction(X_test, Y_test, best_weights, get_acc=True)\n",
    "\n",
    "print(\"Evaluation results\")\n",
    "print(\"Training accuracy: {:.3f}\" .format(train_acc))\n",
    "print(\"Validation accuracy: {:.3f}\" .format(val_acc))\n",
    "print(\"Test accuracy: {:.3f}\" .format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "LinearPerceptron_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
